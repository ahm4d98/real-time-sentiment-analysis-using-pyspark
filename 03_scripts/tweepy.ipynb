{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key='----------------------'\n",
    "consumer_secret='-------------------'\n",
    "access_token ='---------------------'\n",
    "access_secret='---------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweets\n",
      "0   RT @SkySportsNews: Mauricio Pochettino has def...\n",
      "1   RT @MrFilipeOrlando: Put Cristiano Ronaldo in ...\n",
      "2   RT @goal: Cristiano Ronaldo since joining Man ...\n",
      "3   RT @Elite_CR7: Lionel Messi has gone past 112 ...\n",
      "4   RT @CrewsMat10: Lionel Messi received a blow a...\n",
      "..                                                ...\n",
      "95  RT @goal: Cristiano Ronaldo since joining Man ...\n",
      "96  RT @cr7raprhymes: Cristiano Ronaldo scored two...\n",
      "97  RT @Elite_CR7: Lionel Messi has gone past 112 ...\n",
      "98  RT @goal: Lionel Messi makes his first appeara...\n",
      "99  RT @goal: Cristiano Ronaldo since joining Man ...\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from tweepy import API \n",
    "from tweepy import Cursor\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# # # # TWITTER CLIENT # # # #\n",
    "class TwitterClient():\n",
    "    def __init__(self, twitter_user=None):\n",
    "        self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
    "        self.twitter_client = API(self.auth)\n",
    "\n",
    "        self.twitter_user = twitter_user\n",
    "\n",
    "    def get_twitter_client_api(self):\n",
    "        return self.twitter_client\n",
    "\n",
    "    def get_user_timeline_tweets(self, num_tweets):\n",
    "        tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.user_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "\n",
    "    def get_friend_list(self, num_friends):\n",
    "        friend_list = []\n",
    "        for friend in Cursor(self.twitter_client.friends, id=self.twitter_user).items(num_friends):\n",
    "            friend_list.append(friend)\n",
    "        return friend_list\n",
    "\n",
    "    def get_home_timeline_tweets(self, num_tweets):\n",
    "        home_timeline_tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.home_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            home_timeline_tweets.append(tweet)\n",
    "        return home_timeline_tweets\n",
    "\n",
    "\n",
    "# # # # TWITTER AUTHENTICATER # # # #\n",
    "class TwitterAuthenticator():\n",
    "\n",
    "    def authenticate_twitter_app(self):\n",
    "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "        return auth\n",
    "\n",
    "# # # # TWITTER STREAMER # # # #\n",
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.twitter_autenticator = TwitterAuthenticator()    \n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = TwitterListener(fetched_tweets_filename)\n",
    "        auth = self.twitter_autenticator.authenticate_twitter_app() \n",
    "        stream = Stream(auth, listener)\n",
    "\n",
    "        # This line filter Twitter Streams to capture data by the keywords: \n",
    "        stream.filter(track=hash_tag_list)\n",
    "\n",
    "\n",
    "# # # # TWITTER STREAM LISTENER # # # #\n",
    "class TwitterListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            print(data)\n",
    "            with open(self.fetched_tweets_filename, 'a') as tf:\n",
    "                tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True\n",
    "          \n",
    "    def on_error(self, status):\n",
    "        if status == 420:\n",
    "            # Returning False on_data method in case rate limit occurs.\n",
    "            return False\n",
    "        print(status)\n",
    "\n",
    "\n",
    "class TweetAnalyzer():\n",
    "    \"\"\"\n",
    "    Functionality for analyzing and categorizing content from tweets.\n",
    "    \"\"\"\n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    twitter_client = TwitterClient()\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "\n",
    "    api = twitter_client.get_twitter_client_api()\n",
    "\n",
    "    tweets = tweepy.Cursor(api.search,q='Lionel Messi',lang=\"en\",tweetmode='extended').items(1000)\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    #df.to_csv(r'C:\\Users\\ahmed hatem\\Downloads\\live twiiter data\\live tweets for testing.csv')\n",
    "    print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is an attempt to follow the steps in this link : \n",
    "# however i had an error for two days and couldn't find a solution online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "import socket\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsListener(StreamListener):\n",
    "  # tweet object listens for the tweets\n",
    "  def _init_(self, csocket):\n",
    "    self.client_socket = csocket\n",
    "  def on_data(self, data):\n",
    "    try:  \n",
    "      msg = json.loads( data )\n",
    "      print(\"new message\")\n",
    "      # if tweet is longer than 140 characters\n",
    "      if \"extended_tweet\" in msg:\n",
    "        # add at the end of each tweet \"t_end\" \n",
    "        self.client_socket\\\n",
    "            .send(str(msg['extended_tweet']['full_text']+\"t_end\")\\\n",
    "            .encode('utf-8'))         \n",
    "        print(msg['extended_tweet']['full_text'])\n",
    "      else:\n",
    "        # add at the end of each tweet \"t_end\" \n",
    "        self.client_socket\\\n",
    "            .send(str(msg['text']+\"t_end\")\\\n",
    "            .encode('utf-8'))\n",
    "        print(msg['text'])\n",
    "      return True\n",
    "    except BaseException as e:\n",
    "        print(\"Error on_data: %s\" % str(e))\n",
    "    return True\n",
    "  def on_error(self, status):\n",
    "    print(status)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendData(c_socket, keyword):\n",
    "  print('start sending data from Twitter to socket')\n",
    "  # authentication based on the credentials\n",
    "  auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "  auth.set_access_token(access_token, access_secret)\n",
    "  # start sending data from the Streaming API \n",
    "  twitter_stream = Stream(auth, TweetsListener(c_socket))\n",
    "  twitter_stream.filter(track = keyword, languages=[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(lines):\n",
    "    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n",
    "    words = words.na.replace('', None)\n",
    "    words = words.na.drop()\n",
    "    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_detection(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "def subjectivity_detection(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "def text_classification(words):\n",
    "    # polarity detection\n",
    "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
    "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
    "    # subjectivity detection\n",
    "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
    "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session started\n"
     ]
    },
    {
     "ename": "StreamingQueryException",
     "evalue": "Connection refused: connect\n=== Streaming Query ===\nIdentifier: Ahmed [id = a691bb33-6c7d-4852-9ca3-432f9a19cc35, runId = 71c2f108-d803-4b9b-9c7d-90171c9d25bc]\nCurrent Committed Offsets: {}\nCurrent Available Offsets: {TextSocketV2[host: 0.0.0.0, port: 5555]: -1}\n\nCurrent State: ACTIVE\nThread State: RUNNABLE\n\nLogical Plan:\nRepartition 1, true\n+- Project [word#17, polarity#20, subjectivity_detection(word#17) AS subjectivity#24]\n   +- Project [word#17, polarity_detection(word#17) AS polarity#20]\n      +- Project [regexp_replace(word#15, :, , 1) AS word#17]\n         +- Project [regexp_replace(word#13, RT, , 1) AS word#15]\n            +- Project [regexp_replace(word#11, #, , 1) AS word#13]\n               +- Project [regexp_replace(word#9, @\\w+, , 1) AS word#11]\n                  +- Project [regexp_replace(word#6, http\\S+, , 1) AS word#9]\n                     +- Filter AtLeastNNulls(n, word#6)\n                        +- Project [CASE WHEN (word#3 = ) THEN cast(null as string) ELSE word#3 END AS word#6]\n                           +- Project [word#3]\n                              +- Generate explode(split(value#0, t_end, -1)), false, [word#3]\n                                 +- StreamingDataSourceV2Relation [value#0], org.apache.spark.sql.execution.streaming.sources.TextSocketTable$$anon$1@396b89b5, TextSocketV2[host: 0.0.0.0, port: 5555]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStreamingQueryException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a4b64fd8c7e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"checkpointLocation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"C:\\Users\\ahmed hatem\\Downloads\\try\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessingTime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'60 seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\streaming.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStreamingQueryException\u001b[0m: Connection refused: connect\n=== Streaming Query ===\nIdentifier: Ahmed [id = a691bb33-6c7d-4852-9ca3-432f9a19cc35, runId = 71c2f108-d803-4b9b-9c7d-90171c9d25bc]\nCurrent Committed Offsets: {}\nCurrent Available Offsets: {TextSocketV2[host: 0.0.0.0, port: 5555]: -1}\n\nCurrent State: ACTIVE\nThread State: RUNNABLE\n\nLogical Plan:\nRepartition 1, true\n+- Project [word#17, polarity#20, subjectivity_detection(word#17) AS subjectivity#24]\n   +- Project [word#17, polarity_detection(word#17) AS polarity#20]\n      +- Project [regexp_replace(word#15, :, , 1) AS word#17]\n         +- Project [regexp_replace(word#13, RT, , 1) AS word#15]\n            +- Project [regexp_replace(word#11, #, , 1) AS word#13]\n               +- Project [regexp_replace(word#9, @\\w+, , 1) AS word#11]\n                  +- Project [regexp_replace(word#6, http\\S+, , 1) AS word#9]\n                     +- Filter AtLeastNNulls(n, word#6)\n                        +- Project [CASE WHEN (word#3 = ) THEN cast(null as string) ELSE word#3 END AS word#6]\n                           +- Project [word#3]\n                              +- Generate explode(split(value#0, t_end, -1)), false, [word#3]\n                                 +- StreamingDataSourceV2Relation [value#0], org.apache.spark.sql.execution.streaming.sources.TextSocketTable$$anon$1@396b89b5, TextSocketV2[host: 0.0.0.0, port: 5555]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
    "    # read the tweet data from socket\n",
    "    print('session started')\n",
    "    lines = spark.readStream.format(\"socket\").option(\"host\", \"0.0.0.0\").option(\"port\", 5555).load()\n",
    "    # Preprocess the data\n",
    "    words = preprocessing(lines)\n",
    "    # text classification to define polarity and subjectivity\n",
    "    words = text_classification(words)\n",
    "    words = words.repartition(1)\n",
    "    query = words.writeStream.queryName(\"Ahmed\").option(\"host\", \"localhost\")\\\n",
    "        .outputMode(\"append\").format(\"csv\")\\\n",
    "        .option(\"path\", \"./parc\")\\\n",
    "        .option(\"checkpointLocation\", r\"C:\\Users\\ahmed hatem\\Downloads\\try\")\\\n",
    "        .trigger(processingTime='60 seconds').start()\n",
    "    query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
